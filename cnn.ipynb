{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5802cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799937ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisha\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_transforms = v2.Compose([\n",
    "    v2.Resize((64,64)),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomAffine(degrees=0,shear=0.2,scale=(0.8, 1.2)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = datasets.ImageFolder(\n",
    "    root='dataset/training_set',\n",
    "    transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30482874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = v2.Compose([\n",
    "    v2.Resize((64,64)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "test_set = datasets.ImageFolder(\n",
    "    root='dataset/test_set',\n",
    "    transform=test_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7e43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=32 * 16 * 16, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))  \n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))  \n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 16 * 16)  \n",
    "        x = self.relu(self.fc1(x))    \n",
    "        x = self.sigmoid(self.fc2(x)) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d259a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca8e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [1/25], Loss: 0.6565\n",
      "Validation Accuracy: 67.25%\n",
      "Epoch [2/25], Loss: 0.6014\n",
      "Validation Accuracy: 69.95%\n",
      "Epoch [3/25], Loss: 0.5682\n",
      "Validation Accuracy: 71.40%\n",
      "Epoch [4/25], Loss: 0.5329\n",
      "Validation Accuracy: 73.15%\n",
      "Epoch [5/25], Loss: 0.5053\n",
      "Validation Accuracy: 73.35%\n",
      "Epoch [6/25], Loss: 0.4943\n",
      "Validation Accuracy: 75.70%\n",
      "Epoch [7/25], Loss: 0.4794\n",
      "Validation Accuracy: 77.15%\n",
      "Epoch [8/25], Loss: 0.4695\n",
      "Validation Accuracy: 75.45%\n",
      "Epoch [9/25], Loss: 0.4660\n",
      "Validation Accuracy: 77.05%\n",
      "Epoch [10/25], Loss: 0.4508\n",
      "Validation Accuracy: 78.75%\n",
      "Epoch [11/25], Loss: 0.4367\n",
      "Validation Accuracy: 77.60%\n",
      "Epoch [12/25], Loss: 0.4278\n",
      "Validation Accuracy: 75.75%\n",
      "Epoch [13/25], Loss: 0.4141\n",
      "Validation Accuracy: 78.75%\n",
      "Epoch [14/25], Loss: 0.4096\n",
      "Validation Accuracy: 79.45%\n",
      "Epoch [15/25], Loss: 0.3968\n",
      "Validation Accuracy: 77.90%\n",
      "Epoch [16/25], Loss: 0.3941\n",
      "Validation Accuracy: 80.15%\n",
      "Epoch [17/25], Loss: 0.3865\n",
      "Validation Accuracy: 80.35%\n",
      "Epoch [18/25], Loss: 0.3720\n",
      "Validation Accuracy: 78.95%\n",
      "Epoch [19/25], Loss: 0.3683\n",
      "Validation Accuracy: 80.35%\n",
      "Epoch [20/25], Loss: 0.3649\n",
      "Validation Accuracy: 80.00%\n",
      "Epoch [21/25], Loss: 0.3474\n",
      "Validation Accuracy: 79.20%\n",
      "Epoch [22/25], Loss: 0.3510\n",
      "Validation Accuracy: 79.50%\n",
      "Epoch [23/25], Loss: 0.3406\n",
      "Validation Accuracy: 78.45%\n",
      "Epoch [24/25], Loss: 0.3316\n",
      "Validation Accuracy: 80.40%\n",
      "Epoch [25/25], Loss: 0.3315\n",
      "Validation Accuracy: 80.90%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "print(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(\n",
    "            device).float().view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fd81ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.5577730536460876\n",
      "The model predicts the image is a: Dog\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "predict_image = Image.open('dataset/single_prediction/cat_or_dog_2.jpg')\n",
    "predict_image = test_transforms(predict_image).unsqueeze(0).to(device)\n",
    "prediction = model(predict_image)\n",
    "probability = torch.sigmoid(prediction)\n",
    "predicted_class = (probability > 0.5).float()\n",
    "print(predicted_class.item(), probability.item())\n",
    "classes = ['Cat', 'Dog']\n",
    "class_name = classes[int(predicted_class.item())]\n",
    "print(f'The model predicts the image is a: {class_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089d819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
